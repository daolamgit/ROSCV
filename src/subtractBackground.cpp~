#include <ros/ros.h>
#include <stdio.h>
#include <stdlib.h>
#include <iostream>
#include "std_msgs/String.h"
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/imgproc/imgproc.hpp>     //make sure to include the relevant headerfiles
#include <opencv2/highgui/highgui.hpp>
//#include <opencv/cv.h>
//#include <opencv/highgui.h>
//#include <cv_bridge/CvBridge.h>
#include <cvaux.h>
#include<math.h>
#include <cxcore.h>

#include "sensor_msgs/CameraInfo.h"
//#include <highgui.h>
 
/*here is a simple program which demonstrates the use of ros and opencv to do image manipulations on video streams given out as image topics from the monocular vision
of robots,here the device used is a ardrone(quad-rotor).*/
 

using namespace std;
using namespace cv;
namespace enc = sensor_msgs::image_encodings;
RNG rng(12345); 
 
static const char WINDOW[] = "Image window";
const float maxImageWidth = 1280;
  
//subtract Image: make it a member because it is processed by several function
//Mat subtractImage;

class subtractBackground
{
  ros::NodeHandle nh_;
  
  ros::NodeHandle n;
 ros::Publisher pub ; //for publish data, various topics
 ros::Subscriber sub; //for subscribe data

  image_transport::ImageTransport it_;
  image_transport::Subscriber image_sub_; //image subscriber 
  image_transport::Publisher image_pub_; //image publisher(we subscribe to ardrone image_raw)

  //maybe we dont even need it
  std_msgs::String msg;

	
  int thresholdValue;
  int noObject; //number of detected object in the view
  Mat subtractImage, avBkgImage; //for imageProc
  Mat centers; //for undistort image
  Mat undistortCenters; //

  //camera Info
  //Mat D(5, 1, CV_32F, Scalar(0.0)); //vector of 5
  Mat D; //Distort vector 
  Mat K; // camera Matrix 3x3
	
public:
 subtractBackground()
    : it_(nh_)
  {
     
	thresholdValue = 100;	

	namedWindow( WINDOW, CV_WINDOW_AUTOSIZE);
  	createTrackbar( "Threshold:", WINDOW, &thresholdValue, 255 );
	
	avBkgImage = computeAvBkgImage( 5 ); //use 5 Bkg images

	string topic = nh_.resolveName( "image");
	cout << topic <<endl;

	sub = n.subscribe("/cameras/left_hand_camera/camera_info", 1,	 &subtractBackground::getCameraInfo, this);
		
	
	image_sub_ = it_.subscribe(topic, 1, &subtractBackground::imageCb, this);
	image_pub_= it_.advertise("outLeft",1);
  }
 

  ~subtractBackground()
  {
    cv::destroyWindow(WINDOW);
  }
 

  Mat computeAvBkgImage( int nBkgImages ) //must be in the same BkgImages
  {
	
	Mat bkgImage, avBkgImage;
	for (int i= 0; i<nBkgImages; i++)
	{
		string filename;
		ostringstream order;
		order << i;
		filename = "background" + order.str() + ".jpg";
		bkgImage = imread( filename, CV_LOAD_IMAGE_GRAYSCALE);
		if (!bkgImage.data) 
			
			cout << "Error loading file \n";
		if (i==0)
			avBkgImage = bkgImage;
		else
		//avBkgImage += bkgImage;		
		addWeighted( avBkgImage, .5, bkgImage, .5, 0.0, avBkgImage);
	}
	
	return avBkgImage;	
  }


  void imageCb(const sensor_msgs::ImageConstPtr& msg)
  {
 
     //sensor_msgs::CvBridge bridge;//we need this object bridge for facilitating conversion from ros-img to opencv
	//IplImage* img = bridge.imgMsgToCv(msg,"bgr8");  //image being converted from ros to opencv using cvbridge
	cv_bridge::CvImagePtr cv_ptr;
	try
	{
	  cv_ptr = cv_bridge::toCvCopy( msg, enc::BGR8);
	}
	catch (cv_bridge::Exception& e)
	
	{
	  ROS_ERROR( "cv_bridge exception: %s", e.what());
	  return;
	}
	
	Mat img1 = cv_ptr->image;
	IplImage img2 = img1;
	//IplImage* img = &img2;
	
	//use opencv2 i.e. C++
	//subtract image
	//load an average gray bkg
	//sub the img1 from the avBkg
	//blob detect
	//output the blob properties: can be used for grasp
	
	////get the average bkground
	

	
	/////read the new image and subtract from the aveBkgImage
	
	Mat imgGray;
	cvtColor( img1, imgGray, CV_RGB2GRAY); 
	subtractImage = imgGray - avBkgImage;


	//namedWindow( WINDOW, CV_WINDOW_AUTOSIZE);
	imshow(WINDOW, subtractImage);
	waitKey(200);
	
	//update the the dectected object windows
	thresh_callback(thresholdValue, 0);

	undistortCenters = computeUndistortCenters( centers);

}

//i should organize the code after testing
//or i organize now for easy work in future
 void thresh_callback( int thresh, void* )  // don't even need this call back, i.e. can be right in ImgCallback

{
	Mat thresholdOutput;
	vector < vector <Point > > contours;
	vector < Vec4i> hierarchy;
	
	noObject = 0;
	float smallestSize = 150;

	cout << "Callback Trackbar " << thresh << " \n";
	threshold( subtractImage, thresholdOutput, thresh, 255, THRESH_BINARY);
	namedWindow( "Blobs", CV_WINDOW_AUTOSIZE);
	//cvMoveWindow( "Blobs", subtractImage.cols, 0);
	imshow("Blobs", thresholdOutput);


	////detect the contours
	findContours (thresholdOutput, contours, hierarchy, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE, Point( 0, 0));	
	vector <RotatedRect> minRect (contours.size());
	vector <Point2f> minEllipse (contours.size());	
	cout << "Number of contours before filter: " << contours.size() << endl;
	
	//finding the bounding box and filter noise
	//////Consider morphology to connected components in case of 
	//glare object
	for (int i=0; i< contours.size(); i++)
	{	//aapproxPolyDP (Mat (contours[i]), contours_poly [i], 3, true);
		double area0 = contourArea( contours[i]);
		if (area0 > smallestSize)
		{
			minRect[noObject] = minAreaRect ( Mat( contours[i]) );
			noObject ++;
		
		}
	}
	cout << "Number of contours after filter: " << noObject << endl;

	//Drawing bounding box
	Mat drawing = Mat::zeros (thresholdOutput.size(), CV_8UC3);
	for (int i = 0; i< noObject; i++)
	{
		Scalar color = Scalar( rng.uniform(0, 255), rng.uniform( 0, 255), rng.uniform(0, 255));
		//rectangle( drawing, boundRect[i].tl(), boundRect[i].br(), color, 2, 8,  0);
		Point2f rect_points[4];
		minRect[i].points( rect_points);
		for (int j = 0; j< 4; j++)
			
			line( drawing, rect_points[j], rect_points[ (j+1)%4 ], color, 1, 8);

		cout << "Object "<< i <<" angle " << minRect[i].angle << " center: " << minRect[i].center << " size " << minRect[i].size <<endl ;

	}
	namedWindow( "BoundingBox", CV_WINDOW_AUTOSIZE);
	//cvMoveWindow( "BoundingBox", 2*subtractImage.cols, 0);
	imshow("BoundingBox", drawing);


	//compute the undistort, just a few line do I need to make a funtion?
	//convert to Mat to store all the centers
	centers = Mat::zeros( 1, noObject, CV_32FC2);
	for (int i = 0; i< noObject; i++)
		centers.at<Point2f>( 0 , i) = minRect[i].center; 
	cout << "Distort centers: "<< centers <<endl;


	//advertise, publish the centers
	//using streamstring	
	pub = n.advertise< std_msgs::String> ("distortedCenters", 1);
	std_msgs::String msg;
	stringstream ss;
	ss << centers ;
	msg.data = ss.str();
	pub.publish( msg);
	cout << "D: " << D <<endl;
	cout << "K: " << K <<endl;



	//for testing undistort

//	Mat undistortImage;
//	undistort( subtractImage, undistortImage, K, D);
//	namedWindow( "UndistortWindow", CV_WINDOW_AUTOSIZE);
//	imshow( "UndistortWindow", undistortImage);



	//undistortCenters = K* undistortCenters;
	 
}


Mat computeUndistortCenters( Mat distortCenters)
{
	////	computeUndistortCenters(
	if (noObject >0){
		Mat scaledUndistortCenters;
		undistortPoints( centers, scaledUndistortCenters, K, D); //this is a scaled coordinate

		//scale to image space
		Mat undistortCentersTmp = Mat::ones( 3, noObject, CV_64F);
		for (int i = 0; i< noObject; i++)
		{
			undistortCentersTmp.at<double>(0, i) = scaledUndistortCenters.at<Point2f>(0, i).x;
			undistortCentersTmp.at<double>(1, i) = scaledUndistortCenters.at<Point2f>(0, i).y;
		}
		//
		//cout<< undistortCenters <<endl;
		undistortCenters = K* undistortCentersTmp;
		cout << "Undistort centers: " << undistortCenters <<endl;
		return undistortCenters;

	}
	
	

}

void getCameraInfo( const sensor_msgs::CameraInfo::ConstPtr& msg)
{
	static int i= 0;
	i++;
	if (i==1)
	{
	//grab the cam param
		cout << "Camera INFO Callback \n";
		cout << "subscribe callback: \n" << *msg << endl;
		D = Mat::zeros( 5, 1, CV_64F);
		for (int i=0; i< 5; i++)
			D.at<double>(i) = msg->D[i];
		
		
		K = Mat::zeros( 3, 3, CV_64F);
		for (int i=0; i< 3; i++)
		  for (int j=0; j<3; j++)
			K.at<double>(i, j) = msg->K[i*3+ j];

		//adjust the optical center coordinates according to the size of the image
		//baxter camera doesn't change the resolution, it changes the size of the image so 
		//all the intrinsic params don't change except the optical, i.e
		//cNew = cMax* sizeNew/sizeMax;
		//Size currentImageSize avBkgImage.size();
		int currentImageWidth = avBkgImage.cols;
		double scale = / maxImageWidth;
		K.at<double>(0, 2) = K.at<double>(0, 2)* scale;
		K.at<double>(1, 2) = K.at<double>(1, 2)* scale;	
	//get the info and unsubscribe
	
	//n.unsubscribe("/cameras/left_hand_camera/camera_info");
	//ROS_INFO("Left hand camera info :[%s]", msg->data.c_str());
	}
}

 
};



int main(int argc, char** argv)
{
	cout << "Subtracting background \n" ;
	 	
  ros::init(argc, argv, "simple_subtract");
  subtractBackground ic;
  ros::spin();
  
  return 0;
}
